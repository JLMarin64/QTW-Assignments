install.packages("XML")
---
title: "Cherry_Blossom_Code"
author: "Jason Lin, Cho Kim, Jonathan Marin"
date: "January 30, 2019"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r code, include = FALSE}
#Question 17
#p.102
#In Section 2.7, we discovered that the HTML file for the male 2000 results was so poorly formatted that htmlParse() #was unable to fix it to allow us to extract the text table from the <pre> tag.
#In this exercise, we programmatically #edit this HTML file so that we can use htmlParse() as desired.
#To do this, begin by reading the HTML file located at #http://www.cherryblossom.org/cb003m.htm using readLines().
#Carefully examine the HTML displayed in Section 2.7 and #come up with a plan for correcting it.
#Consider whether you want to drop <font>s or close them properly. Once you have #fixed the problem so that the <pre> tag contains the text table, pass your corrected HTML to htmlParse(). You may want #to use a text connection to do this rather than writing the file to disk and reading it in.
#(Page 102).
#p.94
#Loading in the package
library(XML)
#This is the base url
ubase<-"http://www.cherryblossom.org/"
#This is the suffix url to get the 2000 year results
url<-paste0(ubase, "results/2000/Cb003m.htm", sep = "")
#Print the URL
print(url)
#Let's try to use htmlParse to see what happens before we do anything
doc <- htmlParse(url)
preNode = getNodeSet(doc, "//pre")
print(preNode)
knitr::opts_chunk$set(echo = TRUE)
data <- readLines(url)
write.table(data, file = "table.txt", row.names =  FALSE, col.names = FALSE)
data <- gsub("</font><font color=\"#800000\" face=\"Courier New\">", "", data)
#Question 17
#p.102
#In Section 2.7, we discovered that the HTML file for the male 2000 results was so poorly formatted that htmlParse() #was unable to fix it to allow us to extract the text table from the <pre> tag.
#In this exercise, we programmatically #edit this HTML file so that we can use htmlParse() as desired.
#To do this, begin by reading the HTML file located at #http://www.cherryblossom.org/cb003m.htm using readLines().
#Carefully examine the HTML displayed in Section 2.7 and #come up with a plan for correcting it.
#Consider whether you want to drop <font>s or close them properly. Once you have #fixed the problem so that the <pre> tag contains the text table, pass your corrected HTML to htmlParse(). You may want #to use a text connection to do this rather than writing the file to disk and reading it in.
#(Page 102).
#p.94
#Loading in the package
library(XML)
#This is the base url
ubase<-"http://www.cherryblossom.org/"
#This is the suffix url to get the 2000 year results
url<-paste0(ubase, "results/2000/Cb003m.htm", sep = "")
#Print the URL
print(url)
#Let's try to use htmlParse to see what happens before we do anything
doc <- htmlParse(url)
preNode = getNodeSet(doc, "//pre")
print(preNode)
#Read in the HTML
data <- readLines(url)
#Going to take a look at the entire file on text
write.table(data, file = "table.txt", row.names =  FALSE, col.names = FALSE)
#Removing the font from where it is
data <- gsub("</font><font color=\"#800000\" face=\"Courier New\">", "", data)
#Moving font before <pre><stron> and inserting a new line
data <- gsub("<PRE><Strong>","</font><font color=\"#800000\" face=\"Courier New\">\n<PRE><Strong>", data)
data <- gsub("x", "", data)
write.table(data, file = "table.htm", row.names = FALSE, quote = FALSE)
doc2 <- htmlParse("table.htm")
preNode2 = getNodeSet(doc2, "//pre")
preNode2
#preNode2 still looks a little funny with &#13 at the end, but we now have the data that we didn't have before
#after looking this up, that appears to be a carriage return
View(preNode2)
head(preNode2)
?head
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
#Question 17
#p.102
#In Section 2.7, we discovered that the HTML file for the male 2000 results was so poorly formatted that htmlParse() #was unable to fix it to allow us to extract the text table from the <pre> tag.
#In this exercise, we programmatically #edit this HTML file so that we can use htmlParse() as desired.
#To do this, begin by reading the HTML file located at #http://www.cherryblossom.org/cb003m.htm using readLines().
#Carefully examine the HTML displayed in Section 2.7 and #come up with a plan for correcting it.
#Consider whether you want to drop <font>s or close them properly. Once you have #fixed the problem so that the <pre> tag contains the text table, pass your corrected HTML to htmlParse(). You may want #to use a text connection to do this rather than writing the file to disk and reading it in.
#(Page 102).
#p.94
#Loading in the package
library(XML)
#This is the base url
ubase<-"http://www.cherryblossom.org/"
#This is the suffix url to get the 2000 year results
url<-paste0(ubase, "results/2000/Cb003m.htm", sep = "")
#Print the URL
print(url)
#Let's try to use htmlParse to see what happens before we do anything
doc <- htmlParse(url)
preNode = getNodeSet(doc, "//pre")
print(preNode)
#Read in the HTML
data <- readLines(url)
#Going to take a look at the entire file on text
write.table(data, file = "table.txt", row.names =  FALSE, col.names = FALSE)
#Removing the font from where it is
data <- gsub("</font><font color=\"#800000\" face=\"Courier New\">", "", data)
#Moving font before <pre><stron> and inserting a new line
data <- gsub("<PRE><Strong>","</font><font color=\"#800000\" face=\"Courier New\">\n<PRE><Strong>", data)
# could remove this part #
data <- gsub("x", "", data)
write.table(data, file = "table.htm", row.names = FALSE, quote = FALSE)
doc2 <- htmlParse("table.htm")
preNode2 = getNodeSet(doc2, "//pre")
head(preNode2)
#preNode2 still looks a little funny with &#13 at the end, but we now have the data that we didn't have before
#after looking this up, that appears to be a carriage return
#p.94
#Loading in the package
library(XML)
#This is the base url
ubase<-"http://www.cherryblossom.org/"
#This is the suffix url to get the 2000 year results
url<-paste0(ubase, "results/2000/Cb003m.htm", sep = "")
#Print the URL
print(url)
knitr::opts_chunk$set(echo = TRUE)
#p.94
#Loading in the package
library(XML)
#This is the base url
ubase<-"http://www.cherryblossom.org/"
#This is the suffix url to get the 2000 year results
url<-paste0(ubase, "results/2000/Cb003m.htm", sep = "")
#Print the URL
print(url)
View(preNode)
View(preNode)
df <- data.frame(matrix(unlist(preNode2), nrow=3016, byrow=T))
?readLines
