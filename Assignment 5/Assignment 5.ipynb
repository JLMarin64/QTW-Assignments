{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Boston Housing Missing Data Case Study</h1> </center>\n",
    "\n",
    "<center><h2>Cho Kim, Jason Lin, Jonathan Marin</h2> </center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><h2>March 21, 2019</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "For this case study, we are simulating missing data using the Boston Housing dataset from scikit-learn. We started by fitting a linear regressor to the data to establish a loss and goodness of fit baseline to compare later on in the case study. For step 2, we selected a specified percentage of our data within a single column and replaced the value with an imputed value. We compared our loss and goodness of fit baseline from the experiment to our baseline. We then evaluated a \"Missing at Random\" scenario by creating a control scenario for a third variable by making the 1st and 2nd variable randomly missing. We imputed different percentages of the missing data and compared the results. For the final scenario, we evaluated a \"Missing not at Random\" scenario where 25% of our data was missing for a single column. After imputing the missing data, we compared it to our loss and goodness of fit baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Using Sklearn get the Boston Housing dataset.\n",
    "Fit a linear regressor to the data as a baseline.  There is no need to do Cross-Validation.  We are exploring the change in results\n",
    "\n",
    "What is the loss and what are the goodness of fit parameters?  This will be our baseline for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.DataFrame(boston.data, columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections above shows the preliminary views of the Boston Housing Dataset. The document above shows the data dictionary for the different fields in the data set. There is also just a quick view of the different values for the different fields. There are 13 attributes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently there are no missing attribute values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT      target  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "f1_dims = (11.7, 8.27)\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=f1_dims)\n",
    "dist = sns.distplot(boston_df['target'], bins = 30, kde = False)\n",
    "plt.title('Histogram of the Variable Target')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the distribution of the \"target\" variable, and also a table of the summary statistics of the data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston_df.drop(['target'], axis = 1)\n",
    "\n",
    "y = boston_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .33, random_state = 1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['Model', 'MSE', 'R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 23.722599492382468\n",
      "r2: 0.7370653779553855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "model = lm.fit(x_train,y_train)\n",
    "y_pred_base = lm.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred_base)\n",
    "print(\"mse:\", mse)\n",
    "r2 = r2_score(y_test, y_pred_base)\n",
    "print(\"r2:\",r2)\n",
    "\n",
    "base = \"base\"\n",
    "\n",
    "results2 = pd.DataFrame([[\"base\", mse, r2]],columns=['Model', 'MSE', 'R2'])\n",
    "\n",
    "results = results.append(results2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function that is being used as our baseline is the mean squared error, and the goodness of fit parameters is $R^2$. The baseline MSE is 23.72 and the baseline goodness of fit parameter ($R^2$) is 73.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 (repeated)\n",
    "For select between 1, 5 10, 20, 33, and 50% of your data on a single column (Completely at random), replace the present value with a NAN and then perform an imputation of that value.   \n",
    "\n",
    "In each case perform a fit with the imputed data and compare the loss and goodness of fit to your baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PTRATIO'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(x_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PTRATIO` variable was randomly selected. The variable is pupil-teacher ratio by town. \n",
    "\n",
    "We examined the first few rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.08014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.850</td>\n",
       "      <td>41.5</td>\n",
       "      <td>3.9342</td>\n",
       "      <td>5.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.19802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>6.182</td>\n",
       "      <td>42.4</td>\n",
       "      <td>3.9454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>393.63</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.28392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>5.708</td>\n",
       "      <td>74.3</td>\n",
       "      <td>4.7211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>391.13</td>\n",
       "      <td>11.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.05561</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>7.041</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.8278</td>\n",
       "      <td>5.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>371.58</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "37   0.08014   0.0   5.96   0.0  0.499  5.850  41.5  3.9342  5.0  279.0   \n",
       "215  0.19802   0.0  10.59   0.0  0.489  6.182  42.4  3.9454  4.0  277.0   \n",
       "323  0.28392   0.0   7.38   0.0  0.493  5.708  74.3  4.7211  5.0  287.0   \n",
       "299  0.05561  70.0   2.24   0.0  0.400  7.041  10.0  7.8278  5.0  358.0   \n",
       "494  0.27957   0.0   9.69   0.0  0.585  5.926  42.6  2.3817  6.0  391.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "37      19.2  396.90   8.77  \n",
       "215     18.6  393.63   9.47  \n",
       "323     19.6  391.13  11.74  \n",
       "299     14.8  371.58   4.74  \n",
       "494     19.2  396.90  13.59  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 23.54214867356644\n",
      "r2: 0.7390654440888744\n",
      "mse: 23.083480395809946\n",
      "r2: 0.7441491943032842\n",
      "mse: 23.122986582494615\n",
      "r2: 0.7437113188391011\n",
      "mse: 22.83857600351386\n",
      "r2: 0.7468636457210605\n",
      "mse: 22.570198228529968\n",
      "r2: 0.7498382695118986\n",
      "mse: 22.57029493057389\n",
      "r2: 0.7498371976936362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weight_set = {.01, .05, .10, .20, .33,.50}\n",
    "\n",
    "for i in weight_set:\n",
    "    x_train.loc[x_train.sample(frac= i).index, 'PTRATIO'] = np.nan\n",
    "    x_train = x_train.replace(np.nan, x_train['PTRATIO'].mean())\n",
    "    model = lm.fit(x_train,y_train)\n",
    "    y_pred_base = lm.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_base)\n",
    "    print(\"mse:\", mse)\n",
    "    r2 = r2_score(y_test, y_pred_base)\n",
    "    print(\"r2:\",r2)\n",
    "    iteration = \"Step2_\" + str(i) + \" Imputation\"\n",
    "    results2 = pd.DataFrame([[iteration, mse, r2]],columns=['Model', 'MSE', 'R2'])\n",
    "    results = results.append(results2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.01 Imputation</td>\n",
       "      <td>22.570295</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.05 Imputation</td>\n",
       "      <td>23.542149</td>\n",
       "      <td>0.739065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.1 Imputation</td>\n",
       "      <td>23.083480</td>\n",
       "      <td>0.744149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.2 Imputation</td>\n",
       "      <td>23.122987</td>\n",
       "      <td>0.743711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.33 Imputation</td>\n",
       "      <td>22.838576</td>\n",
       "      <td>0.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.5 Imputation</td>\n",
       "      <td>22.570198</td>\n",
       "      <td>0.749838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>23.722599</td>\n",
       "      <td>0.737065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model        MSE        R2\n",
       "0  Step2_0.01 Imputation  22.570295  0.749837\n",
       "0  Step2_0.05 Imputation  23.542149  0.739065\n",
       "0   Step2_0.1 Imputation  23.083480  0.744149\n",
       "0   Step2_0.2 Imputation  23.122987  0.743711\n",
       "0  Step2_0.33 Imputation  22.838576  0.746864\n",
       "0   Step2_0.5 Imputation  22.570198  0.749838\n",
       "0                   base  23.722599  0.737065"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1%\n",
    "The MSE was `23.49` for imputing 1% of the data within a single column. Our baseline MSE was `23.72`. Imputing 1% of the data, reduced the MSE. \n",
    "\n",
    "The $R^2$ was `73.97%` for imputing 1% of the data. Our baseline $R^2$ was `73.71%`. Imputing 1% of the data improved the goodness of fit marginally.\n",
    "\n",
    "### 5%\n",
    "The MSE was `23.69` for imputing 5% of the data. Our baseline MSE was `23.72`. Imputing 5% of the data decreased the MSE less than imputing 1% of the data.\n",
    "\n",
    "The $R^2$ was `73.74%` for imputing 5% of the data. Our baseline $R^2$ was `73.71%`. Imputing 5% of the data improved the goodness of fit by `.03%` which is less than the improvement for imputing 1% of the data. \n",
    "\n",
    "### 10%\n",
    "The MSE was `23.19` for imputing 10% of the data. Our baseline MSE was `23.72`. Imputing 10% of the data decreased the MSE around `.5`. \n",
    "\n",
    "The $R^2$ was `74.30%` for imputing 10% of the data. Our baseline $R^2$ was `73.71%`. Imputing 10% of the data improved the goodness of fit in comparison to the baseline. \n",
    "\n",
    "### 20%\n",
    "The MSE was `22.70` for imputing 20% of the data. Our baseline MSE was `23.72`. Imputing 20% of the data decreased the MSE by `1` in comparison to the baseline.\n",
    "\n",
    "The $R^2$ was `74.83%` for imputing 20% of the data. Our baseline $R^2$ was `73.71%`. Imputing 20% of the data improved the goodness of fit in comparison to the baseline. \n",
    "\n",
    "### 33%\n",
    "The MSE was `22.67` for imputing 33% of the data. Our baseline MSE was `23.72`. Imputing 33% of the data improved the MSE in comparison to the baseline but marginally improved it from 20% by `.03`.\n",
    "\n",
    "The $R^2$ was `74.87%` for imputing 33% of the data. Our baseline $R^2$ was `73.71%`. Imputing 33% of the data improved the goodness of fit compared to the baseline but marginally improved it from 20% by `.04%`.\n",
    "\n",
    "### 50%\n",
    "The MSE was `23.49` for imputing 50% of the data. Our baseline MSE was `23.72`. Imputing 50% of the data reduced the MSE compared to the baseline but did not improve the MSE compared to imputing 33% of the data. \n",
    "\n",
    "The $R^2$ was `73.97%` for imputing 50% of the data. Our baseline $R^2$ was `73.71%`.Imputing 50% of the data improved the goodness of fit in comparison to the baseline, but did not improve it from imputing 33% to 50%. \n",
    "\n",
    "Imputing 50% of the data resulted in identical MSE and $R^2$ values to imputing 1% of the data.\n",
    "\n",
    "### Final Thoughts for Step 2\n",
    "Comparing the different missing data quantities to the base case, we can see that the MSE and R-Square follow a parabolic pattern where in MSE there is a minimum and the R-Square there is a maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "Take 2 different columns and create data “Missing at Random” when controlled for a third variable (i.e if Variable Z is > 30, then Variables X, Y are randomly missing).  Make runs with 10%, 20% and 30% missing data imputed via your best guess.  Repeat your fit and comparisons to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .33, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the random module in Python, we selected 3 variables at random (RM, TAX, and LSTAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RM'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(x_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAX'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(x_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTAT'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(x_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Description                              |\n",
    "|----------|------------------------------------------|\n",
    "| RM       | average number of rooms per dwelling     |\n",
    "| TAX      | full-value property-tax rate per $10,000 |\n",
    "| LSTAT    | lower status of the population           |\n",
    "\n",
    "After examining a few values of the `LSTAT` variable (our variable Z), we decided the threshold for making the `RM` and `TAX` (variables X and Y) variables randomly missing is LSTST values greater than 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37      8.77\n",
       "215     9.47\n",
       "323    11.74\n",
       "299     4.74\n",
       "494    13.59\n",
       "Name: LSTAT, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train['LSTAT'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:5082: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 30.457238965120197\n",
      "r2: 0.6624205278014366\n",
      "mse: 31.011439023521582\n",
      "r2: 0.6562779301936296\n",
      "mse: 31.02435413418321\n",
      "r2: 0.6561347827387493\n"
     ]
    }
   ],
   "source": [
    "weight_set = {.10,.20,.30}\n",
    "\n",
    "for i in weight_set:\n",
    "\n",
    "    change = x_train[x_train['LSTAT']> 10].sample(frac= i)\n",
    "    change.RM = 9999\n",
    "    change.TAX = 9999\n",
    "    x_train.update(change)\n",
    "    x_train.replace(9999,np.nan)\n",
    "    x_train = x_train.replace(np.nan, x_train['RM'].mean())\n",
    "    x_train = x_train.replace(np.nan, x_train['TAX'].mean())\n",
    "    model = lm.fit(x_train,y_train)\n",
    "    y_pred_base = lm.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_base)\n",
    "    print(\"mse:\", mse)\n",
    "    r2 = r2_score(y_test, y_pred_base)\n",
    "    print(\"r2:\",r2)\n",
    "    iteration = \"Step3_\" + str(i) + \" Imputation\"\n",
    "    results2 = pd.DataFrame([[iteration, mse, r2]],columns=['Model', 'MSE', 'R2'])\n",
    "    results = results.append(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.01 Imputation</td>\n",
       "      <td>22.570295</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.05 Imputation</td>\n",
       "      <td>23.542149</td>\n",
       "      <td>0.739065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.1 Imputation</td>\n",
       "      <td>23.083480</td>\n",
       "      <td>0.744149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.2 Imputation</td>\n",
       "      <td>23.122987</td>\n",
       "      <td>0.743711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.33 Imputation</td>\n",
       "      <td>22.838576</td>\n",
       "      <td>0.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.5 Imputation</td>\n",
       "      <td>22.570198</td>\n",
       "      <td>0.749838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.1 Imputation</td>\n",
       "      <td>30.457239</td>\n",
       "      <td>0.662421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.2 Imputation</td>\n",
       "      <td>31.024354</td>\n",
       "      <td>0.656135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.3 Imputation</td>\n",
       "      <td>31.011439</td>\n",
       "      <td>0.656278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>23.722599</td>\n",
       "      <td>0.737065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model        MSE        R2\n",
       "0  Step2_0.01 Imputation  22.570295  0.749837\n",
       "0  Step2_0.05 Imputation  23.542149  0.739065\n",
       "0   Step2_0.1 Imputation  23.083480  0.744149\n",
       "0   Step2_0.2 Imputation  23.122987  0.743711\n",
       "0  Step2_0.33 Imputation  22.838576  0.746864\n",
       "0   Step2_0.5 Imputation  22.570198  0.749838\n",
       "0   Step3_0.1 Imputation  30.457239  0.662421\n",
       "0   Step3_0.2 Imputation  31.024354  0.656135\n",
       "0   Step3_0.3 Imputation  31.011439  0.656278\n",
       "0                   base  23.722599  0.737065"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10%\n",
    "The MSE was `30.46` for imputing 10% of the data missing at random for Step 3. Our baseline MSE was `23.72`. Imputing 10% of the data for Step 3 increased the MSE significantly. \n",
    "\n",
    "The $R^2$ was `66.24%` for imputing 10% of the data. Our baseline $R^2$ was `73.71%`. Imputing 10% of the data did not improve the goodness of fit in comparison to the baseline. \n",
    "\n",
    "### 20%\n",
    "The MSE was `31.02` for imputing 20% of the data missing at random for Step 3. Our baseline MSE was `23.72`. Imputing 20% of the data increased the MSE significantly in comparison to the baseline.\n",
    "\n",
    "The $R^2$ was `65.61%` for imputing 20% of the data. Our baseline $R^2$ was `73.71%`. Imputing 20% of the data did not improve the goodness of fit in comparison to the baseline.\n",
    "\n",
    "### 30%\n",
    "The MSE was `31.01` for imputing 30% of the data. Our baseline MSE was `23.72`. Imputing 30% of the data did not improve the MSE in comparison to the baseline. \n",
    "\n",
    "### Final Thoughts for Step 3\n",
    "The results above show the same parabolic pattern where MSE has a minimum and $R^2$ as a maximum. This seems to indicate that there could be a trade off with missing data, however, this would also depend on influential the variable is in predicting the target.\n",
    "\n",
    "Overall Step 3 had worse metrics than the different percentages of missing data in Step 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "Create a Missing Not at Random pattern in which 25% of the data is missing for a single column.    Impute your data, fit the results and compare to a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:5082: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 25.837527587300777\n",
      "r2: 0.713624109663205\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .33, random_state = 1234)\n",
    "\n",
    "change = x_train[x_train['LSTAT']> 10].sample(frac= .25)\n",
    "change.LSTAT = 9999\n",
    "x_train.update(change)\n",
    "x_train.replace(9999,np.nan)\n",
    "x_train = x_train.replace(np.nan, x_train['LSTAT'].mean())\n",
    "\n",
    "model = lm.fit(x_train,y_train)\n",
    "y_pred_base = lm.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred_base)\n",
    "print(\"mse:\", mse)\n",
    "r2 = r2_score(y_test, y_pred_base)\n",
    "print(\"r2:\",r2)\n",
    "iteration = \"Step4_\" + '0.25' + \" Imputation\"\n",
    "results2 = pd.DataFrame([[iteration, mse, r2]],columns=['Model', 'MSE', 'R2'])\n",
    "results = results.append(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.01 Imputation</td>\n",
       "      <td>22.570295</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.05 Imputation</td>\n",
       "      <td>23.542149</td>\n",
       "      <td>0.739065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.1 Imputation</td>\n",
       "      <td>23.083480</td>\n",
       "      <td>0.744149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.2 Imputation</td>\n",
       "      <td>23.122987</td>\n",
       "      <td>0.743711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.33 Imputation</td>\n",
       "      <td>22.838576</td>\n",
       "      <td>0.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.5 Imputation</td>\n",
       "      <td>22.570198</td>\n",
       "      <td>0.749838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.1 Imputation</td>\n",
       "      <td>30.457239</td>\n",
       "      <td>0.662421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.2 Imputation</td>\n",
       "      <td>31.024354</td>\n",
       "      <td>0.656135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.3 Imputation</td>\n",
       "      <td>31.011439</td>\n",
       "      <td>0.656278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_.25 Imputation</td>\n",
       "      <td>25.763974</td>\n",
       "      <td>0.714439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.2 Imputation</td>\n",
       "      <td>25.500397</td>\n",
       "      <td>0.717361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.25 Imputation</td>\n",
       "      <td>25.837528</td>\n",
       "      <td>0.713624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>23.722599</td>\n",
       "      <td>0.737065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model        MSE        R2\n",
       "0  Step2_0.01 Imputation  22.570295  0.749837\n",
       "0  Step2_0.05 Imputation  23.542149  0.739065\n",
       "0   Step2_0.1 Imputation  23.083480  0.744149\n",
       "0   Step2_0.2 Imputation  23.122987  0.743711\n",
       "0  Step2_0.33 Imputation  22.838576  0.746864\n",
       "0   Step2_0.5 Imputation  22.570198  0.749838\n",
       "0   Step3_0.1 Imputation  30.457239  0.662421\n",
       "0   Step3_0.2 Imputation  31.024354  0.656135\n",
       "0   Step3_0.3 Imputation  31.011439  0.656278\n",
       "0   Step4_.25 Imputation  25.763974  0.714439\n",
       "0   Step4_0.2 Imputation  25.500397  0.717361\n",
       "0  Step4_0.25 Imputation  25.837528  0.713624\n",
       "0                   base  23.722599  0.737065"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the Missing Not at Random pattern at 25% of the data missing, shows MSE is high but not as high as step 3 method for missing data. The same pattern for the $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.5 Imputation</td>\n",
       "      <td>22.570198</td>\n",
       "      <td>0.749838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.01 Imputation</td>\n",
       "      <td>22.570295</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.33 Imputation</td>\n",
       "      <td>22.838576</td>\n",
       "      <td>0.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.1 Imputation</td>\n",
       "      <td>23.083480</td>\n",
       "      <td>0.744149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.2 Imputation</td>\n",
       "      <td>23.122987</td>\n",
       "      <td>0.743711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.05 Imputation</td>\n",
       "      <td>23.542149</td>\n",
       "      <td>0.739065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>23.722599</td>\n",
       "      <td>0.737065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.2 Imputation</td>\n",
       "      <td>25.500397</td>\n",
       "      <td>0.717361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_.25 Imputation</td>\n",
       "      <td>25.763974</td>\n",
       "      <td>0.714439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.25 Imputation</td>\n",
       "      <td>25.837528</td>\n",
       "      <td>0.713624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.1 Imputation</td>\n",
       "      <td>30.457239</td>\n",
       "      <td>0.662421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.3 Imputation</td>\n",
       "      <td>31.011439</td>\n",
       "      <td>0.656278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.2 Imputation</td>\n",
       "      <td>31.024354</td>\n",
       "      <td>0.656135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model        MSE        R2\n",
       "0   Step2_0.5 Imputation  22.570198  0.749838\n",
       "0  Step2_0.01 Imputation  22.570295  0.749837\n",
       "0  Step2_0.33 Imputation  22.838576  0.746864\n",
       "0   Step2_0.1 Imputation  23.083480  0.744149\n",
       "0   Step2_0.2 Imputation  23.122987  0.743711\n",
       "0  Step2_0.05 Imputation  23.542149  0.739065\n",
       "0                   base  23.722599  0.737065\n",
       "0   Step4_0.2 Imputation  25.500397  0.717361\n",
       "0   Step4_.25 Imputation  25.763974  0.714439\n",
       "0  Step4_0.25 Imputation  25.837528  0.713624\n",
       "0   Step3_0.1 Imputation  30.457239  0.662421\n",
       "0   Step3_0.3 Imputation  31.011439  0.656278\n",
       "0   Step3_0.2 Imputation  31.024354  0.656135"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['R2'], ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When sorting by $R^2$, the method in Step 2 gave us the best goodness of fit result that performed better than the baseline. Imputing 50% of the data in Step 2 gave us the highest goodness of fit result out of all of the runs. All of the runs in the Step 3 method had the lowest $R^2$ values out of all of the runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.5 Imputation</td>\n",
       "      <td>22.570198</td>\n",
       "      <td>0.749838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.01 Imputation</td>\n",
       "      <td>22.570295</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.33 Imputation</td>\n",
       "      <td>22.838576</td>\n",
       "      <td>0.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.1 Imputation</td>\n",
       "      <td>23.083480</td>\n",
       "      <td>0.744149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.2 Imputation</td>\n",
       "      <td>23.122987</td>\n",
       "      <td>0.743711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step2_0.05 Imputation</td>\n",
       "      <td>23.542149</td>\n",
       "      <td>0.739065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>23.722599</td>\n",
       "      <td>0.737065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.2 Imputation</td>\n",
       "      <td>25.500397</td>\n",
       "      <td>0.717361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_.25 Imputation</td>\n",
       "      <td>25.763974</td>\n",
       "      <td>0.714439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step4_0.25 Imputation</td>\n",
       "      <td>25.837528</td>\n",
       "      <td>0.713624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.1 Imputation</td>\n",
       "      <td>30.457239</td>\n",
       "      <td>0.662421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.3 Imputation</td>\n",
       "      <td>31.011439</td>\n",
       "      <td>0.656278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step3_0.2 Imputation</td>\n",
       "      <td>31.024354</td>\n",
       "      <td>0.656135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model        MSE        R2\n",
       "0   Step2_0.5 Imputation  22.570198  0.749838\n",
       "0  Step2_0.01 Imputation  22.570295  0.749837\n",
       "0  Step2_0.33 Imputation  22.838576  0.746864\n",
       "0   Step2_0.1 Imputation  23.083480  0.744149\n",
       "0   Step2_0.2 Imputation  23.122987  0.743711\n",
       "0  Step2_0.05 Imputation  23.542149  0.739065\n",
       "0                   base  23.722599  0.737065\n",
       "0   Step4_0.2 Imputation  25.500397  0.717361\n",
       "0   Step4_.25 Imputation  25.763974  0.714439\n",
       "0  Step4_0.25 Imputation  25.837528  0.713624\n",
       "0   Step3_0.1 Imputation  30.457239  0.662421\n",
       "0   Step3_0.3 Imputation  31.011439  0.656278\n",
       "0   Step3_0.2 Imputation  31.024354  0.656135"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['MSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When sorting by MSE, the method in Step 2 gave us the lowest MSE in comparison to the baseline. Imputing 50% of the data in Step 2 resulted in the lowest MSE out of all of the different runs. All of the runs in the Step 3 method had the largest MSE value out of all of the runs. MSE and $R^2$ seem to be directly correlated since sorting by both MSE and $R^2$ yielded the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
